{
  "components": {
    "comp-deploy-model": {
      "executorLabel": "exec-deploy-model",
      "inputDefinitions": {
        "artifacts": {
          "dt_model": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          },
          "rf_model": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "optimal_model_name": {
            "parameterType": "STRING"
          },
          "project": {
            "parameterType": "STRING"
          },
          "region": {
            "parameterType": "STRING"
          },
          "serving_image": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "parameters": {
          "endpoint_name": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-evaluate-model": {
      "executorLabel": "exec-evaluate-model",
      "inputDefinitions": {
        "artifacts": {
          "dt_model": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          },
          "rf_model": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          },
          "test_dataset": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      },
      "outputDefinitions": {
        "parameters": {
          "optimal_model": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-load-data": {
      "executorLabel": "exec-load-data",
      "inputDefinitions": {
        "parameters": {
          "gcs_url": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "output_dataset": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-preprocess-data": {
      "executorLabel": "exec-preprocess-data",
      "inputDefinitions": {
        "artifacts": {
          "input_dataset": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "train_ratio": {
            "defaultValue": 0.7,
            "isOptional": true,
            "parameterType": "NUMBER_DOUBLE"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "test_dataset": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          },
          "train_dataset": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-train-decision-tree": {
      "executorLabel": "exec-train-decision-tree",
      "inputDefinitions": {
        "artifacts": {
          "train_dataset": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "model": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-train-random-forest": {
      "executorLabel": "exec-train-random-forest",
      "inputDefinitions": {
        "artifacts": {
          "train_dataset": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "model": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    }
  },
  "defaultPipelineRoot": "gs://propensity-ml-models/pipeline_root/",
  "deploymentSpec": {
    "executors": {
      "exec-deploy-model": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "deploy_model"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.4.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef deploy_model(\n    optimal_model_name: str,\n    project: str,\n    region: str,\n    serving_image: str,\n    rf_model: Input[Model],\n    dt_model: Input[Model],\n) -> NamedTuple('Outputs', [('endpoint_name', str)]):\n    \"\"\"\n    Deploy the optimal model to a Vertex AI endpoint.\n    \"\"\"\n    # Import necessary libraries within the function\n    from google.cloud import aiplatform\n    import logging\n\n    # Set up logging\n    logging.basicConfig(level=logging.INFO)\n\n    # Initialize the AI Platform client\n    aiplatform.init(project=project, location=region)\n\n    # Select the optimal model based on the name\n    model_mapping = {\n        \"decision_tree\": dt_model,\n        \"random_forest\": rf_model,\n        # Map additional models if necessary\n    }\n    model_to_deploy = model_mapping[optimal_model_name]\n    model_name = 'pet-adoption'\n\n    logging.info(f\"Model URI: {model_to_deploy.uri}\")\n    # Upload model to Vertex AI Model Registry\n    model_upload = aiplatform.Model.upload(\n        display_name=model_name,  \n        artifact_uri=model_to_deploy.uri.rpartition('/')[0],\n        serving_container_image_uri=serving_image,\n        serving_container_health_route=f\"/v1/models/{model_name}\",  \n        serving_container_predict_route=f\"/v1/models/{model_name}:predict\",  \n        serving_container_environment_variables={\"MODEL_NAME\": model_name}  \n    )\n\n    logging.info(f\"Model uploaded: {model_upload.resource_name}\")\n\n    # Create an endpoint\n    endpoint = aiplatform.Endpoint.create(\n        display_name=model_name,\n        project=project,\n        location=region\n    )\n\n    # Deploy model to the endpoint\n    model_deployed = endpoint.deploy(\n        model=model_upload,\n        deployed_model_display_name=model_name,\n        traffic_split={\"0\": 100},\n        machine_type=\"n1-standard-4\"\n    )\n\n    logging.info(f\"Model deployed to endpoint: {endpoint.resource_name}\")\n\n    return (endpoint.resource_name,)\n\n"
          ],
          "image": "europe-west1-docker.pkg.dev/ovocustomer-propensity-nonprod/composer-images-europe-west1-customer-prope-49baaed1-gke/mlops-training"
        }
      },
      "exec-evaluate-model": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "evaluate_model"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.4.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef evaluate_model(\n    test_dataset: Input[Dataset], \n    dt_model: Input[Model],\n    rf_model: Input[Model],\n) -> NamedTuple(\"EvaluationOutput\", [(\"optimal_model\", str)]):\n    \"\"\"\n    Evaluate models on test data and determine the best one based on accuracy.\n    \"\"\"\n    # Import necessary libraries within the function\n    import pandas as pd\n    import joblib\n    import sklearn.metrics as skmetrics\n    import logging\n\n    # Set up logging\n    logging.basicConfig(level=logging.INFO)\n\n    def load_model(model_dir):\n        \"\"\"Load a model from a specified directory.\"\"\"\n        model_path = model_dir.path + \".joblib\"\n        return joblib.load(model_path)\n\n    def evaluate(model, X, y):\n        \"\"\"Evaluate a model and return the accuracy score.\"\"\"\n        predictions = model.predict(X)\n        return skmetrics.accuracy_score(y, predictions)\n\n    # Load the test dataset\n    df = pd.read_csv(test_dataset.path)\n    X_test = df.iloc[:, :-1]\n    y_test = df.iloc[:, -1]\n\n    # Convert categorical columns to 'category' data type for X_test\n    categorical_cols = X_test.select_dtypes(include=['object']).columns\n    X_test[categorical_cols] = X_test[categorical_cols].astype('category')\n\n    # Load models\n    dt = load_model(dt_model)\n    rf = load_model(rf_model)\n\n    # Evaluate models\n    dt_accuracy = evaluate(dt, X_test, y_test)\n    rf_accuracy = evaluate(rf, X_test, y_test)\n\n    # Log metrics\n    logging.info(f\"Decision Tree Accuracy: {dt_accuracy}\")\n    logging.info(f\"Random Forest Accuracy: {rf_accuracy}\")\n\n    # Determine the best model\n    # You can modify the logic here to compare all your models\n    optimal_model = \"decision_tree\" if dt_accuracy > rf_accuracy else \"random_forest\"\n    optimal_accuracy = max(dt_accuracy, rf_accuracy)\n    logging.info(f\"Optimal Model: {optimal_model} with accuracy: {optimal_accuracy}\")\n\n    return (optimal_model,)\n\n"
          ],
          "image": "europe-west1-docker.pkg.dev/ovocustomer-propensity-nonprod/composer-images-europe-west1-customer-prope-49baaed1-gke/mlops-training"
        }
      },
      "exec-load-data": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "load_data"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.4.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef load_data(gcs_url: str, \n              output_dataset: Output[Dataset]\n              ):\n    \"\"\"\n    Download data from a GCS URL and save it to the specified path as a Dataset.\n    \"\"\"\n    # Import necessary libraries within the function\n    from google.cloud import storage\n    import pandas as pd\n\n    # Extract bucket and blob info from GCS URL\n    if not gcs_url.startswith(\"gs://\"):\n        raise ValueError(\"Invalid GCS URL format\")\n    parts = gcs_url[5:].split(\"/\", 1)\n    if len(parts) != 2:\n        raise ValueError(\"Invalid GCS URL format\")\n    bucket_name, blob_name = parts\n\n    # Create a GCS client\n    client = storage.Client()\n    bucket = client.bucket(bucket_name)\n    blob = bucket.blob(blob_name)\n\n    # Read the contents into Pandas DataFrame\n    df = pd.read_csv(blob.open(\"rb\"))\n\n    # Save to the specified path as Dataset\n    df.to_csv(output_dataset.path, index=False)\n    output_dataset.metadata['dataset_metadata'] = {'format': 'csv'}\n\n"
          ],
          "image": "europe-west1-docker.pkg.dev/ovocustomer-propensity-nonprod/composer-images-europe-west1-customer-prope-49baaed1-gke/mlops-training"
        }
      },
      "exec-preprocess-data": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "preprocess_data"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.4.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef preprocess_data(\n    input_dataset: Input[Dataset], \n    train_dataset: Output[Dataset],\n    test_dataset: Output[Dataset],\n    train_ratio: float = 0.7,  # Updated to reflect the 70:30 split\n):\n    \"\"\"\n    Preprocess data by partitioning it into training and testing sets.\n    \"\"\"\n    # Import necessary libraries within the function\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n\n    # Load dataset\n    df = pd.read_csv(input_dataset.path)\n    df = df.dropna()\n\n    # Check if the last column is the target and contains 'Yes'/'No', then convert it to 1/0\n    if set(df.iloc[:, -1].unique()) == {'Yes', 'No'}:\n        df.iloc[:, -1] = df.iloc[:, -1].map({'Yes': 1, 'No': 0})\n\n    # Splitting data into training and testing sets\n    train_data, test_data = train_test_split(df, train_size=train_ratio, random_state=42)\n\n    # Saving the datasets\n    train_data.to_csv(train_dataset.path, index=False)\n    test_data.to_csv(test_dataset.path, index=False)\n\n"
          ],
          "image": "europe-west1-docker.pkg.dev/ovocustomer-propensity-nonprod/composer-images-europe-west1-customer-prope-49baaed1-gke/mlops-training"
        }
      },
      "exec-train-decision-tree": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "train_decision_tree"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.4.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef train_decision_tree(\n    train_dataset: Input[Dataset], \n    model: Output[Model]\n):\n    \"\"\"\n    Train a Decision Tree model with Random Search.\n    \"\"\"\n    # Import necessary libraries within the function\n    import pandas as pd\n    from sklearn.tree import DecisionTreeClassifier\n    from sklearn.model_selection import RandomizedSearchCV\n    from sklearn.metrics import accuracy_score\n    from sklearn.pipeline import Pipeline\n    from sklearn.compose import ColumnTransformer\n    from sklearn.preprocessing import StandardScaler, OneHotEncoder\n    import joblib\n    import logging\n\n    # Set up logging\n    logging.basicConfig(level=logging.INFO)\n\n    # Load training dataset\n    train_df = pd.read_csv(train_dataset.path)\n\n    # Separate features and target. Assuming target is the last column.\n    X_train = train_df.iloc[:, :-1]\n    y_train = train_df.iloc[:, -1]\n\n    # Preprocess features\n    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n\n    numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n    categorical_features = X_train.select_dtypes(include=['object', 'category']).columns\n\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numeric_transformer, numeric_features),\n            ('cat', categorical_transformer, categorical_features)\n        ])\n\n    # Decision Tree classifier\n    classifier = DecisionTreeClassifier(random_state=0)\n\n    # Pipeline\n    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', classifier)])\n\n    # Define search space for hyperparameters\n    param_distributions = {\n        'classifier__max_depth': [None, 10, 20, 30],\n        'classifier__min_samples_split': [2, 5, 10],\n        'classifier__min_samples_leaf': [1, 2, 4],\n        'classifier__max_features': [None, 'auto', 'sqrt', 'log2']\n    }\n\n    # Random search with cross-validation\n    random_search = RandomizedSearchCV(pipeline, param_distributions, n_iter=20, cv=5, n_jobs=-1, random_state=0)\n\n    # Train the model\n    random_search.fit(X_train, y_train)\n\n    # Calculate training accuracy\n    y_train_pred = random_search.predict(X_train)\n    training_accuracy = accuracy_score(y_train, y_train_pred)\n    logging.info(f\"Training Accuracy: {training_accuracy}\")\n\n    # Best model\n    best_model = random_search.best_estimator_\n    logging.info(f\"Best Parameters: {random_search.best_params_}\")\n\n    model.metadata[\"framework\"] = \"DecisionTree\"\n    model.metadata[\"metrics\"] = {\n        \"best_score\": random_search.best_score_,\n        \"training_accuracy\": training_accuracy\n    }\n\n    # Save the model using joblib\n    file_name = model.path + \".joblib\"\n    joblib.dump(best_model, file_name)\n\n"
          ],
          "image": "europe-west1-docker.pkg.dev/ovocustomer-propensity-nonprod/composer-images-europe-west1-customer-prope-49baaed1-gke/mlops-training"
        }
      },
      "exec-train-random-forest": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "train_random_forest"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.4.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef train_random_forest(\n    train_dataset: Input[Dataset], \n    model: Output[Model]\n):\n    \"\"\"\n    Train a Random Forest model with Random Search.\n    \"\"\"\n    # Import necessary libraries within the function\n    import pandas as pd\n    from sklearn.ensemble import RandomForestClassifier\n    from sklearn.model_selection import RandomizedSearchCV\n    from sklearn.metrics import accuracy_score\n    from sklearn.pipeline import Pipeline\n    from sklearn.compose import ColumnTransformer\n    from sklearn.preprocessing import StandardScaler, OneHotEncoder\n    import joblib\n    import logging\n\n    # Set up logging\n    logging.basicConfig(level=logging.INFO)\n\n    # Load training dataset\n    train_df = pd.read_csv(train_dataset.path)\n\n    # Separate features and target. Assuming target is the last column.\n    X_train = train_df.iloc[:, :-1]\n    y_train = train_df.iloc[:, -1]\n\n    # Preprocess features\n    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n\n    numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n    categorical_features = X_train.select_dtypes(include=['object', 'category']).columns\n\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numeric_transformer, numeric_features),\n            ('cat', categorical_transformer, categorical_features)\n        ])\n\n    # Random Forest classifier\n    classifier = RandomForestClassifier(random_state=0)\n\n    # Pipeline\n    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', classifier)])\n\n    # Define search space for hyperparameters\n    param_distributions = {\n        'classifier__n_estimators': [10, 50, 100, 200],\n        'classifier__max_depth': [None, 10, 20, 30],\n        'classifier__min_samples_split': [2, 5, 10],\n        'classifier__min_samples_leaf': [1, 2, 4]\n    }\n\n    # Random search with cross-validation\n    random_search = RandomizedSearchCV(pipeline, param_distributions, n_iter=20, cv=5, n_jobs=-1, random_state=0)\n\n    # Train the model\n    random_search.fit(X_train, y_train)\n\n    # Calculate training accuracy\n    y_train_pred = random_search.predict(X_train)\n    training_accuracy = accuracy_score(y_train, y_train_pred)\n    logging.info(f\"Training Accuracy: {training_accuracy}\")\n\n    # Best model\n    best_model = random_search.best_estimator_\n    logging.info(f\"Best Parameters: {random_search.best_params_}\")\n\n    model.metadata[\"framework\"] = \"RandomForest\"\n    model.metadata[\"metrics\"] = {\n        \"best_score\": random_search.best_score_,\n        \"training_accuracy\": training_accuracy\n    }\n\n    # Save the model using joblib\n    file_name = model.path + \".joblib\"\n    joblib.dump(best_model, file_name)\n\n"
          ],
          "image": "europe-west1-docker.pkg.dev/ovocustomer-propensity-nonprod/composer-images-europe-west1-customer-prope-49baaed1-gke/mlops-training"
        }
      }
    }
  },
  "pipelineInfo": {
    "description": "A pipeline that performs data loading, preprocessing, model training, evaluation, and deployment",
    "name": "ml-platform-pipeline"
  },
  "root": {
    "dag": {
      "tasks": {
        "deploy-model": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-deploy-model"
          },
          "dependentTasks": [
            "evaluate-model",
            "train-decision-tree",
            "train-random-forest"
          ],
          "inputs": {
            "artifacts": {
              "dt_model": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "model",
                  "producerTask": "train-decision-tree"
                }
              },
              "rf_model": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "model",
                  "producerTask": "train-random-forest"
                }
              }
            },
            "parameters": {
              "optimal_model_name": {
                "taskOutputParameter": {
                  "outputParameterKey": "optimal_model",
                  "producerTask": "evaluate-model"
                }
              },
              "project": {
                "runtimeValue": {
                  "constant": "ovocustomer-propensity-nonprod"
                }
              },
              "region": {
                "runtimeValue": {
                  "constant": "europe-west1"
                }
              },
              "serving_image": {
                "runtimeValue": {
                  "constant": "europe-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest"
                }
              }
            }
          },
          "taskInfo": {
            "name": "deploy-model"
          }
        },
        "evaluate-model": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-evaluate-model"
          },
          "dependentTasks": [
            "preprocess-data",
            "train-decision-tree",
            "train-random-forest"
          ],
          "inputs": {
            "artifacts": {
              "dt_model": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "model",
                  "producerTask": "train-decision-tree"
                }
              },
              "rf_model": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "model",
                  "producerTask": "train-random-forest"
                }
              },
              "test_dataset": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "test_dataset",
                  "producerTask": "preprocess-data"
                }
              }
            }
          },
          "taskInfo": {
            "name": "evaluate-model"
          }
        },
        "load-data": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-load-data"
          },
          "inputs": {
            "parameters": {
              "gcs_url": {
                "componentInputParameter": "gcs_url"
              }
            }
          },
          "taskInfo": {
            "name": "load-data"
          }
        },
        "preprocess-data": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-preprocess-data"
          },
          "dependentTasks": [
            "load-data"
          ],
          "inputs": {
            "artifacts": {
              "input_dataset": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "output_dataset",
                  "producerTask": "load-data"
                }
              }
            },
            "parameters": {
              "train_ratio": {
                "componentInputParameter": "train_ratio"
              }
            }
          },
          "taskInfo": {
            "name": "preprocess-data"
          }
        },
        "train-decision-tree": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-train-decision-tree"
          },
          "dependentTasks": [
            "preprocess-data"
          ],
          "inputs": {
            "artifacts": {
              "train_dataset": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "train_dataset",
                  "producerTask": "preprocess-data"
                }
              }
            }
          },
          "taskInfo": {
            "name": "train-decision-tree"
          }
        },
        "train-random-forest": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-train-random-forest"
          },
          "dependentTasks": [
            "preprocess-data"
          ],
          "inputs": {
            "artifacts": {
              "train_dataset": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "train_dataset",
                  "producerTask": "preprocess-data"
                }
              }
            }
          },
          "taskInfo": {
            "name": "train-random-forest"
          }
        }
      }
    },
    "inputDefinitions": {
      "parameters": {
        "gcs_url": {
          "defaultValue": "gs://cloud-samples-data/ai-platform-unified/datasets/tabular/petfinder-tabular-classification.csv",
          "isOptional": true,
          "parameterType": "STRING"
        },
        "train_ratio": {
          "defaultValue": 0.7,
          "isOptional": true,
          "parameterType": "NUMBER_DOUBLE"
        }
      }
    }
  },
  "schemaVersion": "2.1.0",
  "sdkVersion": "kfp-2.4.0"
}